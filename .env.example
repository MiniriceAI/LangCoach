# LangCoach Environment Configuration
# Copy this file to .env and fill in your actual values

# ============================================
# Phase 2: Long-Term Memory Configuration
# ============================================

# Milvus Vector Database (Phase 2 新增)
MILVUS_HOST=milvus                 # Docker 内使用 "milvus"，本地开发使用 "localhost"
MILVUS_PORT=19530                  # Milvus 默认端口

# ============================================
# LLM Provider Configuration (至少配置一个)
# ============================================

# 选项 1: DeepSeek API (推荐 - 高性价比)
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# 选项 2: OpenAI API
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini            # 可选: gpt-4, gpt-4-turbo, gpt-3.5-turbo

# 选项 3: Ollama (本地部署)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b-instruct-q8_0

# ============================================
# Application Configuration
# ============================================

# Gradio Web Server
GRADIO_PORT=8300                   # Phase 2 默认端口改为 8300
GRADIO_FORCE_RESTART=false         # 设置为 true 自动停止占用端口的进程

# Python Configuration
PYTHONUNBUFFERED=1                 # 禁用 Python 输出缓冲

# ============================================
# Docker Volume Directory (可选)
# ============================================

# 用于存储 Milvus/etcd/minio 数据
# DOCKER_VOLUME_DIRECTORY=./volumes

# ============================================
# Memory System Configuration (高级)
# ============================================

# 使用哪个嵌入模型（如果同时配置了 OpenAI 和 Ollama）
# 默认：优先使用 OpenAI (更准确)
# USE_OLLAMA_EMBEDDINGS=false

# 上下文窗口限制（单位：tokens）
# MAX_CONTEXT_TOKENS=3000

# ============================================
# Development Configuration
# ============================================

# 日志级别 (DEBUG, INFO, WARNING, ERROR)
# LOG_LEVEL=INFO

# 是否启用详细调试日志
# DEBUG=false
